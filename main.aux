\relax 
\citation{Mikolov2013Efficient}
\@writefile{toc}{\contentsline {title}{A Chinese Question Answering Approach Integrating Count-based and Embedding-based Features}{1}}
\@writefile{toc}{\authcount {1}}
\@writefile{toc}{\contentsline {author}{No Author Given}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\citation{Mikolov2013Distributed}
\citation{Sun2014Radical}
\citation{Yao2013Answer}
\citation{Wang2015FAQ}
\citation{Yih2013Question}
\citation{Zhou2011Phrase}
\citation{Severyn2013Automatic}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}}
\newlabel{sec:relatedword}{{2}{2}}
\citation{Yu2014Deep}
\citation{Feng2015Applying}
\citation{severyn2015learning}
\citation{Wang2015A}
\citation{Tan2015LSTM}
\citation{Santos2016Attentive}
\citation{Liu2010Language}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methods}{3}}
\newlabel{sec:methods}{{3}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Data Exploration}{3}}
\newlabel{sec:exploration}{{3.1}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The basic information of the training and testing set.}}{3}}
\newlabel{fig:basicinfo}{{1}{3}}
\@writefile{toc}{\contentsline {subsubsection}{Question classification}{3}}
\@writefile{toc}{\contentsline {subsubsection}{Word-level and character-level overlap}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces The number of different types of question.}}{4}}
\newlabel{fig:typeinfo}{{2}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The x-axis means the number of overlapped words in both question and answer sentences. y-axis refers to the probablites of becoming the target answers. }}{4}}
\newlabel{fig:word_overlap}{{1}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The x-axis means the number of overlapped characters in both question and answer sentences. While y-axis refers to the probability of becoming the target answer.}}{4}}
\newlabel{fig:character_overlap}{{2}{4}}
\citation{Liu2010Language}
\@writefile{toc}{\contentsline {subsubsection}{Sequential structure information}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The x-axis refers to the relative position of the overlapped word in a question sentence. x=0 means that the overlapped word is on the front of a sentence while x=100\% is on the back. y-axis means the probality of becoming the correct answer.}}{5}}
\newlabel{fig:word_position}{{3}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Similar to Fig.\nobreakspace  {}3\hbox {}, it shows the relationship between the relative position of the overlapped characters in question sentences and the matching probalities.}}{5}}
\newlabel{fig:character_position}{{4}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Data Preprocessing}{5}}
\newlabel{sec:preprocess}{{3.2}{5}}
\citation{Li2003Learning}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The basic structure of the data prepare}}{6}}
\newlabel{fig:structure}{{5}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Feature Extraction}{6}}
\newlabel{sec:feature}{{3.3}{6}}
\newlabel{sec:categories}{{3.3}{6}}
\@writefile{toc}{\contentsline {subsubsection}{Questions' categories and answers' classfication}{6}}
\citation{Santos2016Attentive}
\@writefile{toc}{\contentsline {subsubsection}{Overlap}{7}}
\newlabel{eq:overlap}{{1}{7}}
\@writefile{toc}{\contentsline {subsubsection}{BM25 score}{7}}
\newlabel{eq:bm25}{{2}{7}}
\newlabel{sec:embedding}{{3.3}{7}}
\@writefile{toc}{\contentsline {subsubsection}{Weighted Embedding}{7}}
\newlabel{eq:representation}{{3}{7}}
\citation{Liu2009Learning}
\citation{Chen2016XGBoost}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces  The structure of our neural network}}{8}}
\newlabel{fig:model}{{6}{8}}
\@writefile{toc}{\contentsline {subsubsection}{Neural network}{8}}
\@writefile{toc}{\contentsline {subsubsection}{Other features}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Model Ensemble}{8}}
\newlabel{sec:model}{{3.4}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{9}}
\newlabel{sec:results}{{4}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Dataset}{9}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Training data structure}}{9}}
\newlabel{tab:table1}{{3}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Evaluation Metrics}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Results}{10}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces The result of our approach.}}{10}}
\newlabel{fig:baselie}{{4}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Discussion}{10}}
\newlabel{discussion}{{4.4}{10}}
\bibdata{nlpcc_qa}
\bibcite{Mikolov2013Efficient}{1}
\bibcite{Mikolov2013Distributed}{2}
\bibcite{Sun2014Radical}{3}
\bibcite{Yao2013Answer}{4}
\bibcite{Wang2015FAQ}{5}
\bibcite{Yih2013Question}{6}
\bibcite{Zhou2011Phrase}{7}
\bibcite{Severyn2013Automatic}{8}
\bibcite{Yu2014Deep}{9}
\bibcite{Feng2015Applying}{10}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion and Future Work}{11}}
\newlabel{sec:conclusion}{{5}{11}}
\bibcite{severyn2015learning}{11}
\bibcite{Wang2015A}{12}
\bibcite{Tan2015LSTM}{13}
\bibcite{Santos2016Attentive}{14}
\bibcite{Liu2010Language}{15}
\bibcite{Li2003Learning}{16}
\bibcite{Liu2009Learning}{17}
\bibcite{Chen2016XGBoost}{18}
\bibstyle{IEEEtran}
